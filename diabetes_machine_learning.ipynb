{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from collections import Counter\n",
    "from sklearn.model_selection import GridSearchCV as gscv\n",
    "\n",
    "#as the gridsearch CV is returning scores even lower than those used without it, we are going to drop that \n",
    "#step for the public output. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a simple exercise involving building a predictive classification algorithm to predict diabetes in a set of Pima Indians using features such as blood pressure, skin thickness, glucose levels, etc. (details mentioned below)\n",
    "\n",
    "This was a dataset of Pima Indians of Central Arizona sourced from the UCI Machine Learning Repository. As of 2014, the majority of the population lives in the federally recognized Gila River Indian Community (GRIC). In historic times a large number of Akimel O'Odham migrated north to occupy the banks of the Salt River, where they formed the Salt River Pima-Maricopa Indian Community (SRPMIC). Both tribes are confederations of two distinct ethnicities, which include the Maricopa.\n",
    "\n",
    "Today the GRIC is a sovereign tribe residing on more than 550,000 acres (2,200 km2) of land in central Arizona. The community is divided into seven districts (similar to states) with a council representing individual subgovernments. It is self-governed by an elected Governor (currently Gregory Mendoza), Lieutenant Governor (currently Stephen Roe-Lewis) and 18-member Tribal Council. The council is elected by district with the number of electees determined by district population. There are more than 19,000 enrolled members overall.\n",
    "\n",
    "The dataset consists of 9 columns of data:\n",
    "\n",
    "1. Number of times pregnant\n",
    "2. Plasma glucose concentration a 2 hours in an oral glucose tolerance test\n",
    "3. Diastolic blood pressure (mm Hg)\n",
    "4. Triceps skin fold thickness (mm)\n",
    "5. 2-Hour serum insulin (mu U/ml)\n",
    "6. Body mass index (weight in kg/(height in m)^2)\n",
    "7. Diabetes pedigree function\n",
    "8. Age (years)\n",
    "9. Class variable of diabetic outcome(0 or 1) \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#loading in the csv as a dataframe\n",
    "\n",
    "df = pd.read_csv('diabetes.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#data source: UCI Machine Learning Repository\n",
    "#https://archive.ics.uci.edu/ml/datasets/pima+indians+diabetes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pregnancies</th>\n",
       "      <th>Glucose</th>\n",
       "      <th>BloodPressure</th>\n",
       "      <th>SkinThickness</th>\n",
       "      <th>Insulin</th>\n",
       "      <th>BMI</th>\n",
       "      <th>DiabetesPedigreeFunction</th>\n",
       "      <th>Age</th>\n",
       "      <th>Outcome</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6</td>\n",
       "      <td>148</td>\n",
       "      <td>72</td>\n",
       "      <td>35</td>\n",
       "      <td>0</td>\n",
       "      <td>33.6</td>\n",
       "      <td>0.627</td>\n",
       "      <td>50</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>85</td>\n",
       "      <td>66</td>\n",
       "      <td>29</td>\n",
       "      <td>0</td>\n",
       "      <td>26.6</td>\n",
       "      <td>0.351</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8</td>\n",
       "      <td>183</td>\n",
       "      <td>64</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>23.3</td>\n",
       "      <td>0.672</td>\n",
       "      <td>32</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>89</td>\n",
       "      <td>66</td>\n",
       "      <td>23</td>\n",
       "      <td>94</td>\n",
       "      <td>28.1</td>\n",
       "      <td>0.167</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>137</td>\n",
       "      <td>40</td>\n",
       "      <td>35</td>\n",
       "      <td>168</td>\n",
       "      <td>43.1</td>\n",
       "      <td>2.288</td>\n",
       "      <td>33</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Pregnancies  Glucose  BloodPressure  SkinThickness  Insulin   BMI  \\\n",
       "0            6      148             72             35        0  33.6   \n",
       "1            1       85             66             29        0  26.6   \n",
       "2            8      183             64              0        0  23.3   \n",
       "3            1       89             66             23       94  28.1   \n",
       "4            0      137             40             35      168  43.1   \n",
       "\n",
       "   DiabetesPedigreeFunction  Age  Outcome  \n",
       "0                     0.627   50        1  \n",
       "1                     0.351   31        0  \n",
       "2                     0.672   32        1  \n",
       "3                     0.167   21        0  \n",
       "4                     2.288   33        1  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correlations: \n",
      "\n",
      "0.466581398307\n",
      "0.221898153034\n",
      "0.0650683595503\n",
      "0.0747522319183\n",
      "0.130547954884\n",
      "0.292694662644\n",
      "0.173844065653\n",
      "0.238355983027\n"
     ]
    }
   ],
   "source": [
    "from scipy.stats import pearsonr as pr\n",
    "\n",
    "#As we can see, there are no strong correlations between any individual value and a diabetic outcome, using pearson's r \n",
    "#as a measurement of correlation\n",
    "\n",
    "cor = pr(df['Glucose'], df['Outcome'])\n",
    "cor2 = pr(df['Pregnancies'], df['Outcome'])\n",
    "cor3 = pr(df['BloodPressure'], df['Outcome'])\n",
    "cor4 = pr(df['SkinThickness'], df['Outcome'])\n",
    "cor5 = pr(df['Insulin'], df['Outcome'])\n",
    "cor6 = pr(df['BMI'], df['Outcome'])\n",
    "cor7 = pr(df['DiabetesPedigreeFunction'], df['Outcome'])\n",
    "cor8 = pr(df['Age'], df['Outcome'])\n",
    "\n",
    "print 'Correlations: '\n",
    "print \"\"\n",
    "print cor[0]\n",
    "print cor2[0]\n",
    "print cor3[0]\n",
    "print cor4[0]\n",
    "print cor5[0]\n",
    "print cor6[0]\n",
    "print cor7[0]\n",
    "print cor8[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "As seen from the figures above, there are no statistically significant correlations between any individual feature and a diabetic outcome. \n",
    "\n",
    "However, when we combine all the data features and use them together to predict the outcome, the results are a lot more promising. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#loading in the big guns\n",
    "#all classifiers are we are attempting to build a classifier that takes all features as input and returns the best \n",
    "#F1 score\n",
    "\n",
    "from sklearn.svm import SVC \n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis as QDA\n",
    "from sklearn.ensemble import RandomForestClassifier as RFC\n",
    "from sklearn.naive_bayes import GaussianNB as NB\n",
    "from sklearn.neighbors import KNeighborsClassifier as KNC\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.linear_model import LogisticRegression as reg\n",
    "\n",
    "#the train-test splitter\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#train_test splitter\n",
    "f = df[['Pregnancies', 'Glucose', 'BloodPressure', 'SkinThickness', 'Insulin', \n",
    "                          'BMI', 'DiabetesPedigreeFunction', 'Age']].as_matrix()\n",
    "\n",
    "l = df['Outcome'].as_matrix()\n",
    "\n",
    "f_train, f_test, l_train, l_test = train_test_split(f, l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#here is the saved copy of the train-test split that yields the highest results. \n",
    "import pickle\n",
    "\"\"\"\n",
    "with open('f_train.pkl', 'wb') as f:\n",
    "    pickle.dump(f_train, f)\n",
    "    \n",
    "with open('f_test.pkl', 'wb') as f:\n",
    "    pickle.dump(f_test, f)\n",
    "    \n",
    "with open('l_train.pkl', 'wb') as f:\n",
    "    pickle.dump(l_train, f)\n",
    "    \n",
    "with open('l_test.pkl', 'wb') as f:\n",
    "    pickle.dump(l_test, f)\n",
    "\"\"\"\n",
    "\n",
    "with open('f_train.pkl', 'rb') as f:\n",
    "    f_train = pickle.load(f)\n",
    "    \n",
    "with open('f_test.pkl', 'rb') as f:\n",
    "    f_test = pickle.load(f)\n",
    "    \n",
    "with open('l_train.pkl', 'rb') as f:\n",
    "    l_train = pickle.load(f)\n",
    "    \n",
    "with open('l_test.pkl', 'rb') as f:\n",
    "    l_test = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#function to choose between small set of classifiers. \n",
    "\n",
    "def try_clf(f_train, f_test, l_train, l_test):\n",
    "    svc_clf = SVC(kernel='linear')\n",
    "    qda_clf = QDA()\n",
    "    rfc_clf = RFC()\n",
    "    nb_clf = NB()\n",
    "    knc_clf = KNC()\n",
    "    reg_clf = reg()\n",
    "    \n",
    "    svc_clf.fit(f_train, l_train)\n",
    "    svc_pred_lst = svc_clf.predict(f_test)\n",
    "    print 'SVC results'\n",
    "    print \"\"\n",
    "    print classification_report(l_test, svc_pred_lst, target_names = [\"diabetic\", \"non-diabetic\"])\n",
    "    print \"\"\n",
    "    print \"\"\n",
    "    \n",
    "    qda_clf.fit(f_train, l_train)\n",
    "    qda_pred_lst = qda_clf.predict(f_test)\n",
    "    print 'QDA results'\n",
    "    print \"\"\n",
    "    print classification_report(l_test, qda_pred_lst, target_names = [\"diabetic\", \"non-diabetic\"])\n",
    "    print \"\"\n",
    "    print \"\"\n",
    "    \n",
    "    rfc_clf.fit(f_train, l_train)\n",
    "    rfc_pred_lst = rfc_clf.predict(f_test)\n",
    "    print 'RFC results'\n",
    "    print \"\"\n",
    "    print classification_report(l_test, rfc_pred_lst, target_names = [\"diabetic\", \"non-diabetic\"])\n",
    "    print \"\"\n",
    "    print \"\"\n",
    "    \n",
    "    nb_clf.fit(f_train, l_train)\n",
    "    nb_pred_lst = nb_clf.predict(f_test)\n",
    "    print 'Gaussian Naive Bayes results'\n",
    "    print \"\"\n",
    "    print classification_report(l_test, nb_pred_lst, target_names = [\"diabetic\", \"non-diabetic\"])\n",
    "    print \"\"\n",
    "    print \"\"\n",
    "    \n",
    "    knc_clf.fit(f_train, l_train)\n",
    "    knc_pred_lst = knc_clf.predict(f_test)\n",
    "    print 'KNC results'\n",
    "    print \"\"\n",
    "    print classification_report(l_test, knc_pred_lst, target_names = [\"diabetic\", \"non-diabetic\"])\n",
    "    print \"\"\n",
    "    print \"\"\n",
    "    \n",
    "    reg_clf.fit(f_train, l_train)\n",
    "    reg_pred_lst = reg_clf.predict(f_test)\n",
    "    print 'Logistic Regression results'\n",
    "    print \"\"\n",
    "    print classification_report(l_test, reg_pred_lst, target_names = [\"diabetic\", \"non-diabetic\"])\n",
    "    print \"\"\n",
    "    print \"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see from the results below we were able to achieve an F1 score of nearly 80% on our logistic regression classifier as well as our Support Vector Machine classifier, this can be further improved with more data and hypertuning of parameters being used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVC results\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    diabetic       0.82      0.87      0.85       123\n",
      "non-diabetic       0.74      0.67      0.70        69\n",
      "\n",
      " avg / total       0.79      0.80      0.79       192\n",
      "\n",
      "\n",
      "\n",
      "QDA results\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    diabetic       0.82      0.84      0.83       123\n",
      "non-diabetic       0.70      0.68      0.69        69\n",
      "\n",
      " avg / total       0.78      0.78      0.78       192\n",
      "\n",
      "\n",
      "\n",
      "RFC results\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    diabetic       0.79      0.87      0.83       123\n",
      "non-diabetic       0.71      0.58      0.64        69\n",
      "\n",
      " avg / total       0.76      0.77      0.76       192\n",
      "\n",
      "\n",
      "\n",
      "Gaussian Naive Bayes results\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    diabetic       0.83      0.81      0.82       123\n",
      "non-diabetic       0.68      0.70      0.69        69\n",
      "\n",
      " avg / total       0.77      0.77      0.77       192\n",
      "\n",
      "\n",
      "\n",
      "KNC results\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    diabetic       0.78      0.77      0.78       123\n",
      "non-diabetic       0.60      0.61      0.60        69\n",
      "\n",
      " avg / total       0.71      0.71      0.71       192\n",
      "\n",
      "\n",
      "\n",
      "Logistic Regression results\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    diabetic       0.81      0.89      0.85       123\n",
      "non-diabetic       0.77      0.62      0.69        69\n",
      "\n",
      " avg / total       0.79      0.80      0.79       192\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "try_clf(f_train, f_test, l_train, l_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
